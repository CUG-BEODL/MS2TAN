{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_patches=100,             num_positions=1000,             patch_dim_in=864,             patch_dim_out=864\n",
      "num_patches=144,             num_positions=1440,             patch_dim_in=600,             patch_dim_out=600\n",
      "num_patches=225,             num_positions=2250,             patch_dim_in=384,             patch_dim_out=384\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "num_frame = 10\n",
    "num_channel = 6\n",
    "img_size = 120\n",
    "\n",
    "model = MS2TAN(\n",
    "    dim_list=[256, 192, 128],\n",
    "    num_frame=num_frame,\n",
    "    image_size=img_size,\n",
    "    patch_list=[12, 10, 8],\n",
    "    in_chans=num_channel,\n",
    "    out_chans=num_channel,\n",
    "    depth_list=[2, 2, 2],\n",
    "    heads_list=[8, 6, 4],\n",
    "    dim_head_list=[32, 32, 32],\n",
    ").to(device)\n",
    "init_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 4.59M\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total params: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# input and output time-series images\n",
    "X = torch.randn(batch_size, num_frame, num_channel, img_size, img_size).to(device)\n",
    "y = torch.randn(batch_size, num_frame, num_channel, img_size, img_size).to(device)\n",
    "\n",
    "# artificial masked pixels in trainset\n",
    "artificial = torch.randn(batch_size, num_frame, 1, img_size, img_size).to(device)\n",
    "\n",
    "# hint tensor for each missing pixels (both artificial and real)\n",
    "hint_tensor = torch.randn(batch_size, num_frame, 1, img_size, img_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediate result 0: torch.Size([1, 10, 6, 120, 120])\n",
      "Immediate result 1: torch.Size([1, 10, 6, 120, 120])\n",
      "Immediate result 2: torch.Size([1, 10, 6, 120, 120])\n",
      "Final result: torch.Size([1, 10, 6, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "out = model(X, (hint_tensor, artificial), y, mode='val')\n",
    "\n",
    "# each immediate result\n",
    "out_list = out['hist_list']\n",
    "for idx, res in enumerate(out_list):\n",
    "    print(f'Immediate result {idx}:', res.shape)\n",
    "\n",
    "# final result after replacement\n",
    "final_result = out['replace_out']\n",
    "print(f'Final result:', final_result.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
